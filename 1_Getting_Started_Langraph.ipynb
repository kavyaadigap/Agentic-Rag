{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFqqI3E8Xn4"
      },
      "source": [
        "## Chatbots With Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDGN7B1e8cX_",
        "outputId": "72a6b2d2-b5c0-4b21-fa0d-2d1bb4985267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langgraph) (0.3.66)\n",
            "Collecting langgraph-checkpoint>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt>=0.5.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.72-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langgraph) (2.7.4)\n",
            "Collecting xxhash>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith) (3.10.5)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith) (24.1)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.4.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
            "Requirement already satisfied: sniffio in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.12.2)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
            "     ---------------------------------------- 0.0/44.7 kB ? eta -:--:--\n",
            "     --------- ------------------------------ 10.2/44.7 kB ? eta -:--:--\n",
            "     -------------------------------------- 44.7/44.7 kB 732.6 kB/s eta 0:00:00\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langsmith) (2.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Downloading langgraph-0.5.0-py3-none-any.whl (143 kB)\n",
            "   ---------------------------------------- 0.0/143.7 kB ? eta -:--:--\n",
            "   ----------- ---------------------------- 41.0/143.7 kB ? eta -:--:--\n",
            "   ----------- ---------------------------- 41.0/143.7 kB ? eta -:--:--\n",
            "   -------------------------------- ----- 122.9/143.7 kB 901.1 kB/s eta 0:00:01\n",
            "   -------------------------------------- 143.7/143.7 kB 855.2 kB/s eta 0:00:00\n",
            "Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "   ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 43.8/43.8 kB 2.1 MB/s eta 0:00:00\n",
            "Downloading langgraph_prebuilt-0.5.1-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.72-py3-none-any.whl (50 kB)\n",
            "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 50.1/50.1 kB 1.3 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
            "Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl (121 kB)\n",
            "   ---------------------------------------- 0.0/121.4 kB ? eta -:--:--\n",
            "   ------------------------------------- -- 112.6/121.4 kB 3.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 121.4/121.4 kB 1.8 MB/s eta 0:00:00\n",
            "Installing collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.5.0 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.5.1 langgraph-sdk-0.1.72 ormsgpack-1.10.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSj_MR1AHBs",
        "outputId": "207a3ab4-0503-4b6b-fa24-d630d7cc66a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (0.3.26)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (0.3.66)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Collecting groq<1,>=0.28.0 (from langchain_groq)\n",
            "  Downloading groq-0.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (3.11.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from groq<1,>=0.28.0->langchain_groq) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from groq<1,>=0.28.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from groq<1,>=0.28.0->langchain_groq) (0.27.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from groq<1,>=0.28.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from groq<1,>=0.28.0->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.18.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.28.0->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kavyasree p\\miniconda3\\envs\\myenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Downloading langchain_groq-0.3.4-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.29.0-py3-none-any.whl (130 kB)\n",
            "   ---------------------------------------- 0.0/130.8 kB ? eta -:--:--\n",
            "   --------- ----------------------------- 30.7/130.8 kB 660.6 kB/s eta 0:00:01\n",
            "   ------------------ --------------------- 61.4/130.8 kB 1.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- -- 122.9/130.8 kB 901.1 kB/s eta 0:00:01\n",
            "   -------------------------------------- 130.8/130.8 kB 772.9 kB/s eta 0:00:00\n",
            "Installing collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.29.0 langchain_groq-0.3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgKIrwXJAjgA",
        "outputId": "7eec3700-d2d7-4ca3-bc2c-875c9cae1dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "# it was in googlr colab, you would use the following lines to set up your environment:\n",
        "\n",
        "# from google.colab import userdata\n",
        "# groq_api_key=userdata.get('groq_api_key')\n",
        "# langsmith=userdata.get('LANGSMITH_API_KEY')\n",
        "# print(langsmith)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFpKBPoZBQAa"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGGRAPH_PROJECT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJZl9uX-CFo7"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9vOWf8yCJ4W",
        "outputId": "91931387-650d-4d7a-95de-31735c66ce27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7efbfa765330>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7efbfa764670>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDc7RviFCVKB"
      },
      "source": [
        "## Start Building Chatbot Using Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bPcSBey6CUeF"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dVzn-8rrC6-7"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgjwX6BQDcfk",
        "outputId": "10f24dc5-6242-454b-b61c-cfecf260ae22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7efbfa91fee0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOF74t5GDeJO"
      },
      "outputs": [],
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m7NDe74EPGW"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKFbmbqcEVIq",
        "outputId": "9f91e0af-022e-4485-8151-db69c5cc3ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7efbfa91fee0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jBWX44IEWy-"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN4O63shEtyZ"
      },
      "outputs": [],
      "source": [
        "graph=graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_PPER3gfEygm",
        "outputId": "fbe87a93-4e15-47e7-9cc3-5cebe43ce64f"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvjUFmxFCwU",
        "outputId": "c77c0d85-b6f5-4dee-81c5-5c728019aaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: hello\n",
            "dict_values([{'messages': AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_time': 0.028948375, 'prompt_time': 0.00232277, 'queue_time': None, 'total_time': 0.031271145}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c991b84-1ff6-461a-baa7-08c8d2767d10-0', usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30})}])\n",
            "content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n' response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_time': 0.028948375, 'prompt_time': 0.00232277, 'queue_time': None, 'total_time': 0.031271145}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-7c991b84-1ff6-461a-baa7-08c8d2767d10-0' usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30}\n",
            "Assistant: Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\n",
            "\n",
            "User: what is generative ai\n",
            "dict_values([{'messages': AIMessage(content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\\n\\n* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\\n\\n* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\\n\\n**Examples:**\\n\\n* **Text Generation:**\\n\\nChatGPT (like me!), writing stories, poems, articles, dialogue\\n\\n* **Image Generation:**\\n\\nDALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\\n\\n* **Audio Generation:**\\n\\nJukebox, Amper Music composing music in various styles\\n\\n* **Code Generation:**\\n\\nGitHub Copilot assisting developers in writing code\\n\\n**How it works:**\\n\\nGenerative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\\n\\n* **Generator:** Creates new content.\\n* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\\n\\nThrough this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative Arts:** Writing, music composition, art generation\\n* **Design:** Creating prototypes, generating marketing materials\\n* **Entertainment:** Developing interactive stories, generating game assets\\n* **Research:** Exploring new scientific concepts, simulating experiments\\n* **Education:** Personalized learning experiences, creating interactive learning materials\\n\\n**Ethical Considerations:**\\n\\nWhile generative AI offers exciting possibilities, it also raises ethical concerns:\\n\\n* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\\n* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\n\\n\\nLet me know if you have any more questions about generative AI!\\n\", response_metadata={'token_usage': {'completion_tokens': 501, 'prompt_tokens': 18, 'total_tokens': 519, 'completion_time': 1.044149282, 'prompt_time': 0.002699907, 'queue_time': None, 'total_time': 1.046849189}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b200b57-a482-45f9-a07c-4fa92c425157-0', usage_metadata={'input_tokens': 18, 'output_tokens': 501, 'total_tokens': 519})}])\n",
            "content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\\n\\n* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\\n\\n* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\\n\\n**Examples:**\\n\\n* **Text Generation:**\\n\\nChatGPT (like me!), writing stories, poems, articles, dialogue\\n\\n* **Image Generation:**\\n\\nDALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\\n\\n* **Audio Generation:**\\n\\nJukebox, Amper Music composing music in various styles\\n\\n* **Code Generation:**\\n\\nGitHub Copilot assisting developers in writing code\\n\\n**How it works:**\\n\\nGenerative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\\n\\n* **Generator:** Creates new content.\\n* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\\n\\nThrough this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative Arts:** Writing, music composition, art generation\\n* **Design:** Creating prototypes, generating marketing materials\\n* **Entertainment:** Developing interactive stories, generating game assets\\n* **Research:** Exploring new scientific concepts, simulating experiments\\n* **Education:** Personalized learning experiences, creating interactive learning materials\\n\\n**Ethical Considerations:**\\n\\nWhile generative AI offers exciting possibilities, it also raises ethical concerns:\\n\\n* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\\n* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\n\\n\\nLet me know if you have any more questions about generative AI!\\n\" response_metadata={'token_usage': {'completion_tokens': 501, 'prompt_tokens': 18, 'total_tokens': 519, 'completion_time': 1.044149282, 'prompt_time': 0.002699907, 'queue_time': None, 'total_time': 1.046849189}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-6b200b57-a482-45f9-a07c-4fa92c425157-0' usage_metadata={'input_tokens': 18, 'output_tokens': 501, 'total_tokens': 519}\n",
            "Assistant: Generative AI is a type of artificial intelligence that focuses on creating new content. \n",
            "\n",
            "Think of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "**What it does:**\n",
            "\n",
            "* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\n",
            "\n",
            "* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\n",
            "\n",
            "* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\n",
            "\n",
            "**Examples:**\n",
            "\n",
            "* **Text Generation:**\n",
            "\n",
            "ChatGPT (like me!), writing stories, poems, articles, dialogue\n",
            "\n",
            "* **Image Generation:**\n",
            "\n",
            "DALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\n",
            "\n",
            "* **Audio Generation:**\n",
            "\n",
            "Jukebox, Amper Music composing music in various styles\n",
            "\n",
            "* **Code Generation:**\n",
            "\n",
            "GitHub Copilot assisting developers in writing code\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "Generative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\n",
            "\n",
            "* **Generator:** Creates new content.\n",
            "* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\n",
            "\n",
            "Through this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "Generative AI has a wide range of potential applications, including:\n",
            "\n",
            "* **Creative Arts:** Writing, music composition, art generation\n",
            "* **Design:** Creating prototypes, generating marketing materials\n",
            "* **Entertainment:** Developing interactive stories, generating game assets\n",
            "* **Research:** Exploring new scientific concepts, simulating experiments\n",
            "* **Education:** Personalized learning experiences, creating interactive learning materials\n",
            "\n",
            "**Ethical Considerations:**\n",
            "\n",
            "While generative AI offers exciting possibilities, it also raises ethical concerns:\n",
            "\n",
            "* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\n",
            "* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\n",
            "* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Let me know if you have any more questions about generative AI!\n",
            "\n",
            "User: q\n",
            "Good Bye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\",\"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant:\",value[\"messages\"].content)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
